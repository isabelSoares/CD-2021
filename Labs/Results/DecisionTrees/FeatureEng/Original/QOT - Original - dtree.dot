digraph Tree {
node [shape=box, style="filled, rounded", color="black", fontname=helvetica] ;
edge [fontname=helvetica] ;
0 [label=<X<SUB>4</SUB> &le; 0.5<br/>entropy = 0.411<br/>samples = 6294<br/>value = [5775, 519]<br/>class = negative>, fillcolor="#e78c4b"] ;
1 [label=<X<SUB>49</SUB> &le; 0.5<br/>entropy = 0.361<br/>samples = 6005<br/>value = [5592, 413]<br/>class = negative>, fillcolor="#e78a48"] ;
0 -> 1 [labeldistance=2.5, labelangle=45, headlabel="True"] ;
2 [label=<X<SUB>48</SUB> &le; 0.5<br/>entropy = 0.333<br/>samples = 5803<br/>value = [5447, 356]<br/>class = negative>, fillcolor="#e78946"] ;
1 -> 2 ;
3 [label=<X<SUB>93</SUB> &le; 0.5<br/>entropy = 0.315<br/>samples = 5682<br/>value = [5359, 323]<br/>class = negative>, fillcolor="#e78945"] ;
2 -> 3 ;
4 [label=<X<SUB>102</SUB> &le; 0.5<br/>entropy = 0.294<br/>samples = 5526<br/>value = [5240, 286]<br/>class = negative>, fillcolor="#e68844"] ;
3 -> 4 ;
5 [label=<X<SUB>73</SUB> &le; 0.5<br/>entropy = 0.271<br/>samples = 5193<br/>value = [4952, 241]<br/>class = negative>, fillcolor="#e68743"] ;
4 -> 5 ;
6 [label=<X<SUB>50</SUB> &le; 0.5<br/>entropy = 0.254<br/>samples = 5062<br/>value = [4847, 215]<br/>class = negative>, fillcolor="#e68742"] ;
5 -> 6 ;
7 [label=<X<SUB>101</SUB> &le; 0.5<br/>entropy = 0.235<br/>samples = 4839<br/>value = [4653, 186]<br/>class = negative>, fillcolor="#e68641"] ;
6 -> 7 ;
8 [label=<X<SUB>52</SUB> &le; 0.5<br/>entropy = 0.222<br/>samples = 4681<br/>value = [4514, 167]<br/>class = negative>, fillcolor="#e68640"] ;
7 -> 8 ;
9 [label=<X<SUB>38</SUB> &le; 0.5<br/>entropy = 0.211<br/>samples = 4609<br/>value = [4455, 154]<br/>class = negative>, fillcolor="#e68540"] ;
8 -> 9 ;
10 [label=<X<SUB>55</SUB> &le; 0.5<br/>entropy = 0.199<br/>samples = 4482<br/>value = [4343, 139]<br/>class = negative>, fillcolor="#e6853f"] ;
9 -> 10 ;
11 [label=<X<SUB>5</SUB> &le; 0.5<br/>entropy = 0.18<br/>samples = 4048<br/>value = [3938, 110]<br/>class = negative>, fillcolor="#e6853f"] ;
10 -> 11 ;
12 [label=<X<SUB>76</SUB> &le; 0.5<br/>entropy = 0.208<br/>samples = 2814<br/>value = [2722, 92]<br/>class = negative>, fillcolor="#e68540"] ;
11 -> 12 ;
13 [label=<X<SUB>59</SUB> &le; 0.5<br/>entropy = 0.199<br/>samples = 2784<br/>value = [2698, 86]<br/>class = negative>, fillcolor="#e6853f"] ;
12 -> 13 ;
14 [label=<X<SUB>94</SUB> &le; 0.5<br/>entropy = 0.207<br/>samples = 2638<br/>value = [2552, 86]<br/>class = negative>, fillcolor="#e68540"] ;
13 -> 14 ;
15 [label=<X<SUB>44</SUB> &le; 0.5<br/>entropy = 0.232<br/>samples = 2014<br/>value = [1938, 76]<br/>class = negative>, fillcolor="#e68641"] ;
14 -> 15 ;
16 [label=<X<SUB>69</SUB> &le; 0.5<br/>entropy = 0.22<br/>samples = 1983<br/>value = [1913, 70]<br/>class = negative>, fillcolor="#e68640"] ;
15 -> 16 ;
17 [label=<X<SUB>97</SUB> &le; 0.5<br/>entropy = 0.227<br/>samples = 1905<br/>value = [1835, 70]<br/>class = negative>, fillcolor="#e68641"] ;
16 -> 17 ;
18 [label=<X<SUB>66</SUB> &le; 0.5<br/>entropy = 0.205<br/>samples = 1622<br/>value = [1570, 52]<br/>class = negative>, fillcolor="#e68540"] ;
17 -> 18 ;
19 [label=<X<SUB>13</SUB> &le; 0.5<br/>entropy = 0.265<br/>samples = 709<br/>value = [677, 32]<br/>class = negative>, fillcolor="#e68742"] ;
18 -> 19 ;
20 [label=<entropy = 0.249<br/>samples = 698<br/>value = [669, 29]<br/>class = negative>, fillcolor="#e68642"] ;
19 -> 20 ;
21 [label=<entropy = 0.845<br/>samples = 11<br/>value = [8, 3]<br/>class = negative>, fillcolor="#efb083"] ;
19 -> 21 ;
22 [label=<X<SUB>6</SUB> &le; 0.5<br/>entropy = 0.152<br/>samples = 913<br/>value = [893, 20]<br/>class = negative>, fillcolor="#e6843d"] ;
18 -> 22 ;
23 [label=<entropy = 0.14<br/>samples = 909<br/>value = [891, 18]<br/>class = negative>, fillcolor="#e6843d"] ;
22 -> 23 ;
24 [label=<entropy = 1.0<br/>samples = 4<br/>value = [2, 2]<br/>class = negative>, fillcolor="#ffffff"] ;
22 -> 24 ;
25 [label=<X<SUB>56</SUB> &le; 0.5<br/>entropy = 0.342<br/>samples = 283<br/>value = [265, 18]<br/>class = negative>, fillcolor="#e78a46"] ;
17 -> 25 ;
26 [label=<X<SUB>30</SUB> &le; 0.5<br/>entropy = 0.293<br/>samples = 272<br/>value = [258, 14]<br/>class = negative>, fillcolor="#e68844"] ;
25 -> 26 ;
27 [label=<entropy = 0.265<br/>samples = 267<br/>value = [255, 12]<br/>class = negative>, fillcolor="#e68742"] ;
26 -> 27 ;
28 [label=<entropy = 0.971<br/>samples = 5<br/>value = [3, 2]<br/>class = negative>, fillcolor="#f6d5bd"] ;
26 -> 28 ;
29 [label=<entropy = 0.946<br/>samples = 11<br/>value = [7, 4]<br/>class = negative>, fillcolor="#f4c9aa"] ;
25 -> 29 ;
30 [label=<entropy = 0.0<br/>samples = 78<br/>value = [78, 0]<br/>class = negative>, fillcolor="#e58139"] ;
16 -> 30 ;
31 [label=<X<SUB>33</SUB> &le; 0.5<br/>entropy = 0.709<br/>samples = 31<br/>value = [25, 6]<br/>class = negative>, fillcolor="#eb9f69"] ;
15 -> 31 ;
32 [label=<entropy = 0.579<br/>samples = 29<br/>value = [25, 4]<br/>class = negative>, fillcolor="#e99559"] ;
31 -> 32 ;
33 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = positive>, fillcolor="#399de5"] ;
31 -> 33 ;
34 [label=<X<SUB>37</SUB> &le; 0.5<br/>entropy = 0.119<br/>samples = 624<br/>value = [614, 10]<br/>class = negative>, fillcolor="#e5833c"] ;
14 -> 34 ;
35 [label=<X<SUB>44</SUB> &le; 0.5<br/>entropy = 0.047<br/>samples = 385<br/>value = [383, 2]<br/>class = negative>, fillcolor="#e5823a"] ;
34 -> 35 ;
36 [label=<entropy = 0.0<br/>samples = 275<br/>value = [275, 0]<br/>class = negative>, fillcolor="#e58139"] ;
35 -> 36 ;
37 [label=<X<SUB>89</SUB> &le; 0.5<br/>entropy = 0.131<br/>samples = 110<br/>value = [108, 2]<br/>class = negative>, fillcolor="#e5833d"] ;
35 -> 37 ;
38 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = positive>, fillcolor="#399de5"] ;
37 -> 38 ;
39 [label=<X<SUB>36</SUB> &le; 0.5<br/>entropy = 0.075<br/>samples = 109<br/>value = [108, 1]<br/>class = negative>, fillcolor="#e5823b"] ;
37 -> 39 ;
40 [label=<entropy = 0.0<br/>samples = 104<br/>value = [104, 0]<br/>class = negative>, fillcolor="#e58139"] ;
39 -> 40 ;
41 [label=<entropy = 0.722<br/>samples = 5<br/>value = [4, 1]<br/>class = negative>, fillcolor="#eca06a"] ;
39 -> 41 ;
42 [label=<X<SUB>33</SUB> &le; 0.5<br/>entropy = 0.212<br/>samples = 239<br/>value = [231, 8]<br/>class = negative>, fillcolor="#e68540"] ;
34 -> 42 ;
43 [label=<X<SUB>90</SUB> &le; 0.5<br/>entropy = 0.151<br/>samples = 230<br/>value = [225, 5]<br/>class = negative>, fillcolor="#e6843d"] ;
42 -> 43 ;
44 [label=<entropy = 0.103<br/>samples = 222<br/>value = [219, 3]<br/>class = negative>, fillcolor="#e5833c"] ;
43 -> 44 ;
45 [label=<entropy = 0.811<br/>samples = 8<br/>value = [6, 2]<br/>class = negative>, fillcolor="#eeab7b"] ;
43 -> 45 ;
46 [label=<entropy = 0.918<br/>samples = 9<br/>value = [6, 3]<br/>class = negative>, fillcolor="#f2c09c"] ;
42 -> 46 ;
47 [label=<entropy = 0.0<br/>samples = 146<br/>value = [146, 0]<br/>class = negative>, fillcolor="#e58139"] ;
13 -> 47 ;
48 [label=<entropy = 0.722<br/>samples = 30<br/>value = [24, 6]<br/>class = negative>, fillcolor="#eca06a"] ;
12 -> 48 ;
49 [label=<X<SUB>87</SUB> &le; 0.5<br/>entropy = 0.11<br/>samples = 1234<br/>value = [1216, 18]<br/>class = negative>, fillcolor="#e5833c"] ;
11 -> 49 ;
50 [label=<X<SUB>21</SUB> &le; 0.5<br/>entropy = 0.092<br/>samples = 1199<br/>value = [1185, 14]<br/>class = negative>, fillcolor="#e5823b"] ;
49 -> 50 ;
51 [label=<X<SUB>34</SUB> &le; 0.5<br/>entropy = 0.081<br/>samples = 1188<br/>value = [1176, 12]<br/>class = negative>, fillcolor="#e5823b"] ;
50 -> 51 ;
52 [label=<X<SUB>53</SUB> &le; 0.5<br/>entropy = 0.071<br/>samples = 1175<br/>value = [1165, 10]<br/>class = negative>, fillcolor="#e5823b"] ;
51 -> 52 ;
53 [label=<X<SUB>96</SUB> &le; 0.5<br/>entropy = 0.055<br/>samples = 1109<br/>value = [1102, 7]<br/>class = negative>, fillcolor="#e5823a"] ;
52 -> 53 ;
54 [label=<entropy = 0.043<br/>samples = 1060<br/>value = [1055, 5]<br/>class = negative>, fillcolor="#e5823a"] ;
53 -> 54 ;
55 [label=<X<SUB>66</SUB> &le; 0.5<br/>entropy = 0.246<br/>samples = 49<br/>value = [47, 2]<br/>class = negative>, fillcolor="#e68641"] ;
53 -> 55 ;
56 [label=<entropy = 0.619<br/>samples = 13<br/>value = [11, 2]<br/>class = negative>, fillcolor="#ea985d"] ;
55 -> 56 ;
57 [label=<entropy = 0.0<br/>samples = 36<br/>value = [36, 0]<br/>class = negative>, fillcolor="#e58139"] ;
55 -> 57 ;
58 [label=<X<SUB>42</SUB> &le; 0.5<br/>entropy = 0.267<br/>samples = 66<br/>value = [63, 3]<br/>class = negative>, fillcolor="#e68742"] ;
52 -> 58 ;
59 [label=<X<SUB>94</SUB> &le; 0.5<br/>entropy = 0.198<br/>samples = 65<br/>value = [63, 2]<br/>class = negative>, fillcolor="#e6853f"] ;
58 -> 59 ;
60 [label=<entropy = 0.0<br/>samples = 56<br/>value = [56, 0]<br/>class = negative>, fillcolor="#e58139"] ;
59 -> 60 ;
61 [label=<entropy = 0.764<br/>samples = 9<br/>value = [7, 2]<br/>class = negative>, fillcolor="#eca572"] ;
59 -> 61 ;
62 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = positive>, fillcolor="#399de5"] ;
58 -> 62 ;
63 [label=<X<SUB>46</SUB> &le; 0.5<br/>entropy = 0.619<br/>samples = 13<br/>value = [11, 2]<br/>class = negative>, fillcolor="#ea985d"] ;
51 -> 63 ;
64 [label=<entropy = 0.0<br/>samples = 10<br/>value = [10, 0]<br/>class = negative>, fillcolor="#e58139"] ;
63 -> 64 ;
65 [label=<entropy = 0.918<br/>samples = 3<br/>value = [1, 2]<br/>class = positive>, fillcolor="#9ccef2"] ;
63 -> 65 ;
66 [label=<entropy = 0.684<br/>samples = 11<br/>value = [9, 2]<br/>class = negative>, fillcolor="#eb9d65"] ;
50 -> 66 ;
67 [label=<X<SUB>67</SUB> &le; 0.5<br/>entropy = 0.513<br/>samples = 35<br/>value = [31, 4]<br/>class = negative>, fillcolor="#e89153"] ;
49 -> 67 ;
68 [label=<entropy = 0.431<br/>samples = 34<br/>value = [31, 3]<br/>class = negative>, fillcolor="#e88d4c"] ;
67 -> 68 ;
69 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = positive>, fillcolor="#399de5"] ;
67 -> 69 ;
70 [label=<X<SUB>33</SUB> &le; 0.5<br/>entropy = 0.354<br/>samples = 434<br/>value = [405, 29]<br/>class = negative>, fillcolor="#e78a47"] ;
10 -> 70 ;
71 [label=<X<SUB>41</SUB> &le; 0.5<br/>entropy = 0.299<br/>samples = 416<br/>value = [394, 22]<br/>class = negative>, fillcolor="#e68844"] ;
70 -> 71 ;
72 [label=<X<SUB>59</SUB> &le; 0.5<br/>entropy = 0.235<br/>samples = 365<br/>value = [351, 14]<br/>class = negative>, fillcolor="#e68641"] ;
71 -> 72 ;
73 [label=<X<SUB>82</SUB> &le; 0.5<br/>entropy = 0.199<br/>samples = 355<br/>value = [344, 11]<br/>class = negative>, fillcolor="#e6853f"] ;
72 -> 73 ;
74 [label=<X<SUB>29</SUB> &le; 0.5<br/>entropy = 0.159<br/>samples = 344<br/>value = [336, 8]<br/>class = negative>, fillcolor="#e6843e"] ;
73 -> 74 ;
75 [label=<X<SUB>3</SUB> &le; 0.5<br/>entropy = 0.13<br/>samples = 333<br/>value = [327, 6]<br/>class = negative>, fillcolor="#e5833d"] ;
74 -> 75 ;
76 [label=<entropy = 0.096<br/>samples = 322<br/>value = [318, 4]<br/>class = negative>, fillcolor="#e5833b"] ;
75 -> 76 ;
77 [label=<entropy = 0.684<br/>samples = 11<br/>value = [9, 2]<br/>class = negative>, fillcolor="#eb9d65"] ;
75 -> 77 ;
78 [label=<entropy = 0.684<br/>samples = 11<br/>value = [9, 2]<br/>class = negative>, fillcolor="#eb9d65"] ;
74 -> 78 ;
79 [label=<entropy = 0.845<br/>samples = 11<br/>value = [8, 3]<br/>class = negative>, fillcolor="#efb083"] ;
73 -> 79 ;
80 [label=<X<SUB>8</SUB> &le; 0.5<br/>entropy = 0.881<br/>samples = 10<br/>value = [7, 3]<br/>class = negative>, fillcolor="#f0b78e"] ;
72 -> 80 ;
81 [label=<entropy = 0.544<br/>samples = 8<br/>value = [7, 1]<br/>class = negative>, fillcolor="#e99355"] ;
80 -> 81 ;
82 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = positive>, fillcolor="#399de5"] ;
80 -> 82 ;
83 [label=<entropy = 0.627<br/>samples = 51<br/>value = [43, 8]<br/>class = negative>, fillcolor="#ea985e"] ;
71 -> 83 ;
84 [label=<X<SUB>87</SUB> &le; 0.5<br/>entropy = 0.964<br/>samples = 18<br/>value = [11, 7]<br/>class = negative>, fillcolor="#f6d1b7"] ;
70 -> 84 ;
85 [label=<entropy = 0.837<br/>samples = 15<br/>value = [11, 4]<br/>class = negative>, fillcolor="#eeaf81"] ;
84 -> 85 ;
86 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = positive>, fillcolor="#399de5"] ;
84 -> 86 ;
87 [label=<X<SUB>59</SUB> &le; 0.5<br/>entropy = 0.524<br/>samples = 127<br/>value = [112, 15]<br/>class = negative>, fillcolor="#e89254"] ;
9 -> 87 ;
88 [label=<X<SUB>24</SUB> &le; 0.5<br/>entropy = 0.331<br/>samples = 115<br/>value = [108, 7]<br/>class = negative>, fillcolor="#e78946"] ;
87 -> 88 ;
89 [label=<entropy = 0.232<br/>samples = 106<br/>value = [102, 4]<br/>class = negative>, fillcolor="#e68641"] ;
88 -> 89 ;
90 [label=<X<SUB>43</SUB> &le; 0.5<br/>entropy = 0.918<br/>samples = 9<br/>value = [6, 3]<br/>class = negative>, fillcolor="#f2c09c"] ;
88 -> 90 ;
91 [label=<entropy = 0.0<br/>samples = 5<br/>value = [5, 0]<br/>class = negative>, fillcolor="#e58139"] ;
90 -> 91 ;
92 [label=<X<SUB>40</SUB> &le; 0.5<br/>entropy = 0.811<br/>samples = 4<br/>value = [1, 3]<br/>class = positive>, fillcolor="#7bbeee"] ;
90 -> 92 ;
93 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = positive>, fillcolor="#399de5"] ;
92 -> 93 ;
94 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = negative>, fillcolor="#e58139"] ;
92 -> 94 ;
95 [label=<X<SUB>71</SUB> &le; 0.5<br/>entropy = 0.918<br/>samples = 12<br/>value = [4, 8]<br/>class = positive>, fillcolor="#9ccef2"] ;
87 -> 95 ;
96 [label=<X<SUB>43</SUB> &le; 0.5<br/>entropy = 0.503<br/>samples = 9<br/>value = [1, 8]<br/>class = positive>, fillcolor="#52a9e8"] ;
95 -> 96 ;
97 [label=<entropy = 0.0<br/>samples = 8<br/>value = [0, 8]<br/>class = positive>, fillcolor="#399de5"] ;
96 -> 97 ;
98 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = negative>, fillcolor="#e58139"] ;
96 -> 98 ;
99 [label=<entropy = 0.0<br/>samples = 3<br/>value = [3, 0]<br/>class = negative>, fillcolor="#e58139"] ;
95 -> 99 ;
100 [label=<X<SUB>32</SUB> &le; 0.5<br/>entropy = 0.681<br/>samples = 72<br/>value = [59, 13]<br/>class = negative>, fillcolor="#eb9d65"] ;
8 -> 100 ;
101 [label=<entropy = 0.569<br/>samples = 67<br/>value = [58, 9]<br/>class = negative>, fillcolor="#e99558"] ;
100 -> 101 ;
102 [label=<X<SUB>42</SUB> &le; 0.5<br/>entropy = 0.722<br/>samples = 5<br/>value = [1, 4]<br/>class = positive>, fillcolor="#6ab6ec"] ;
100 -> 102 ;
103 [label=<entropy = 0.0<br/>samples = 4<br/>value = [0, 4]<br/>class = positive>, fillcolor="#399de5"] ;
102 -> 103 ;
104 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = negative>, fillcolor="#e58139"] ;
102 -> 104 ;
105 [label=<X<SUB>71</SUB> &le; 0.5<br/>entropy = 0.53<br/>samples = 158<br/>value = [139, 19]<br/>class = negative>, fillcolor="#e99254"] ;
7 -> 105 ;
106 [label=<X<SUB>42</SUB> &le; 0.5<br/>entropy = 0.609<br/>samples = 127<br/>value = [108, 19]<br/>class = negative>, fillcolor="#ea975c"] ;
105 -> 106 ;
107 [label=<X<SUB>78</SUB> &le; 0.5<br/>entropy = 0.555<br/>samples = 124<br/>value = [108, 16]<br/>class = negative>, fillcolor="#e99456"] ;
106 -> 107 ;
108 [label=<X<SUB>97</SUB> &le; 0.5<br/>entropy = 0.627<br/>samples = 102<br/>value = [86, 16]<br/>class = negative>, fillcolor="#ea985e"] ;
107 -> 108 ;
109 [label=<X<SUB>89</SUB> &le; 0.5<br/>entropy = 0.515<br/>samples = 87<br/>value = [77, 10]<br/>class = negative>, fillcolor="#e89153"] ;
108 -> 109 ;
110 [label=<X<SUB>13</SUB> &le; 0.5<br/>entropy = 0.657<br/>samples = 53<br/>value = [44, 9]<br/>class = negative>, fillcolor="#ea9b61"] ;
109 -> 110 ;
111 [label=<X<SUB>94</SUB> &le; 0.5<br/>entropy = 0.577<br/>samples = 51<br/>value = [44, 7]<br/>class = negative>, fillcolor="#e99558"] ;
110 -> 111 ;
112 [label=<X<SUB>63</SUB> &le; 0.5<br/>entropy = 0.482<br/>samples = 48<br/>value = [43, 5]<br/>class = negative>, fillcolor="#e89050"] ;
111 -> 112 ;
113 [label=<X<SUB>82</SUB> &le; 0.5<br/>entropy = 0.42<br/>samples = 47<br/>value = [43, 4]<br/>class = negative>, fillcolor="#e78d4b"] ;
112 -> 113 ;
114 [label=<entropy = 0.276<br/>samples = 42<br/>value = [40, 2]<br/>class = negative>, fillcolor="#e68743"] ;
113 -> 114 ;
115 [label=<entropy = 0.971<br/>samples = 5<br/>value = [3, 2]<br/>class = negative>, fillcolor="#f6d5bd"] ;
113 -> 115 ;
116 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = positive>, fillcolor="#399de5"] ;
112 -> 116 ;
117 [label=<entropy = 0.918<br/>samples = 3<br/>value = [1, 2]<br/>class = positive>, fillcolor="#9ccef2"] ;
111 -> 117 ;
118 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = positive>, fillcolor="#399de5"] ;
110 -> 118 ;
119 [label=<X<SUB>74</SUB> &le; 0.5<br/>entropy = 0.191<br/>samples = 34<br/>value = [33, 1]<br/>class = negative>, fillcolor="#e6853f"] ;
109 -> 119 ;
120 [label=<entropy = 0.0<br/>samples = 32<br/>value = [32, 0]<br/>class = negative>, fillcolor="#e58139"] ;
119 -> 120 ;
121 [label=<entropy = 1.0<br/>samples = 2<br/>value = [1, 1]<br/>class = negative>, fillcolor="#ffffff"] ;
119 -> 121 ;
122 [label=<entropy = 0.971<br/>samples = 15<br/>value = [9, 6]<br/>class = negative>, fillcolor="#f6d5bd"] ;
108 -> 122 ;
123 [label=<entropy = 0.0<br/>samples = 22<br/>value = [22, 0]<br/>class = negative>, fillcolor="#e58139"] ;
107 -> 123 ;
124 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = positive>, fillcolor="#399de5"] ;
106 -> 124 ;
125 [label=<entropy = 0.0<br/>samples = 31<br/>value = [31, 0]<br/>class = negative>, fillcolor="#e58139"] ;
105 -> 125 ;
126 [label=<X<SUB>0</SUB> &le; 0.5<br/>entropy = 0.558<br/>samples = 223<br/>value = [194, 29]<br/>class = negative>, fillcolor="#e99457"] ;
6 -> 126 ;
127 [label=<X<SUB>76</SUB> &le; 0.5<br/>entropy = 0.463<br/>samples = 204<br/>value = [184, 20]<br/>class = negative>, fillcolor="#e88f4f"] ;
126 -> 127 ;
128 [label=<X<SUB>59</SUB> &le; 0.5<br/>entropy = 0.39<br/>samples = 196<br/>value = [181, 15]<br/>class = negative>, fillcolor="#e78b49"] ;
127 -> 128 ;
129 [label=<X<SUB>37</SUB> &le; 0.5<br/>entropy = 0.324<br/>samples = 186<br/>value = [175, 11]<br/>class = negative>, fillcolor="#e78945"] ;
128 -> 129 ;
130 [label=<X<SUB>72</SUB> &le; 0.5<br/>entropy = 0.213<br/>samples = 148<br/>value = [143, 5]<br/>class = negative>, fillcolor="#e68540"] ;
129 -> 130 ;
131 [label=<X<SUB>91</SUB> &le; 0.5<br/>entropy = 0.18<br/>samples = 147<br/>value = [143, 4]<br/>class = negative>, fillcolor="#e6853f"] ;
130 -> 131 ;
132 [label=<X<SUB>16</SUB> &le; 0.5<br/>entropy = 0.145<br/>samples = 145<br/>value = [142, 3]<br/>class = negative>, fillcolor="#e6843d"] ;
131 -> 132 ;
133 [label=<entropy = 0.107<br/>samples = 142<br/>value = [140, 2]<br/>class = negative>, fillcolor="#e5833c"] ;
132 -> 133 ;
134 [label=<entropy = 0.918<br/>samples = 3<br/>value = [2, 1]<br/>class = negative>, fillcolor="#f2c09c"] ;
132 -> 134 ;
135 [label=<entropy = 1.0<br/>samples = 2<br/>value = [1, 1]<br/>class = negative>, fillcolor="#ffffff"] ;
131 -> 135 ;
136 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = positive>, fillcolor="#399de5"] ;
130 -> 136 ;
137 [label=<X<SUB>44</SUB> &le; 0.5<br/>entropy = 0.629<br/>samples = 38<br/>value = [32, 6]<br/>class = negative>, fillcolor="#ea995e"] ;
129 -> 137 ;
138 [label=<X<SUB>40</SUB> &le; 0.5<br/>entropy = 0.503<br/>samples = 36<br/>value = [32, 4]<br/>class = negative>, fillcolor="#e89152"] ;
137 -> 138 ;
139 [label=<entropy = 0.422<br/>samples = 35<br/>value = [32, 3]<br/>class = negative>, fillcolor="#e78d4c"] ;
138 -> 139 ;
140 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = positive>, fillcolor="#399de5"] ;
138 -> 140 ;
141 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = positive>, fillcolor="#399de5"] ;
137 -> 141 ;
142 [label=<X<SUB>97</SUB> &le; 0.5<br/>entropy = 0.971<br/>samples = 10<br/>value = [6, 4]<br/>class = negative>, fillcolor="#f6d5bd"] ;
128 -> 142 ;
143 [label=<entropy = 0.0<br/>samples = 4<br/>value = [4, 0]<br/>class = negative>, fillcolor="#e58139"] ;
142 -> 143 ;
144 [label=<entropy = 0.918<br/>samples = 6<br/>value = [2, 4]<br/>class = positive>, fillcolor="#9ccef2"] ;
142 -> 144 ;
145 [label=<X<SUB>80</SUB> &le; 0.5<br/>entropy = 0.954<br/>samples = 8<br/>value = [3, 5]<br/>class = positive>, fillcolor="#b0d8f5"] ;
127 -> 145 ;
146 [label=<entropy = 0.0<br/>samples = 5<br/>value = [0, 5]<br/>class = positive>, fillcolor="#399de5"] ;
145 -> 146 ;
147 [label=<entropy = 0.0<br/>samples = 3<br/>value = [3, 0]<br/>class = negative>, fillcolor="#e58139"] ;
145 -> 147 ;
148 [label=<X<SUB>98</SUB> &le; 0.5<br/>entropy = 0.998<br/>samples = 19<br/>value = [10, 9]<br/>class = negative>, fillcolor="#fcf2eb"] ;
126 -> 148 ;
149 [label=<X<SUB>44</SUB> &le; 0.5<br/>entropy = 0.863<br/>samples = 14<br/>value = [10, 4]<br/>class = negative>, fillcolor="#efb388"] ;
148 -> 149 ;
150 [label=<entropy = 0.0<br/>samples = 9<br/>value = [9, 0]<br/>class = negative>, fillcolor="#e58139"] ;
149 -> 150 ;
151 [label=<X<SUB>62</SUB> &le; 0.5<br/>entropy = 0.722<br/>samples = 5<br/>value = [1, 4]<br/>class = positive>, fillcolor="#6ab6ec"] ;
149 -> 151 ;
152 [label=<entropy = 0.0<br/>samples = 4<br/>value = [0, 4]<br/>class = positive>, fillcolor="#399de5"] ;
151 -> 152 ;
153 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = negative>, fillcolor="#e58139"] ;
151 -> 153 ;
154 [label=<entropy = 0.0<br/>samples = 5<br/>value = [0, 5]<br/>class = positive>, fillcolor="#399de5"] ;
148 -> 154 ;
155 [label=<X<SUB>97</SUB> &le; 0.5<br/>entropy = 0.719<br/>samples = 131<br/>value = [105, 26]<br/>class = negative>, fillcolor="#eba06a"] ;
5 -> 155 ;
156 [label=<X<SUB>0</SUB> &le; 0.5<br/>entropy = 0.283<br/>samples = 61<br/>value = [58, 3]<br/>class = negative>, fillcolor="#e68843"] ;
155 -> 156 ;
157 [label=<entropy = 0.126<br/>samples = 58<br/>value = [57, 1]<br/>class = negative>, fillcolor="#e5833c"] ;
156 -> 157 ;
158 [label=<entropy = 0.918<br/>samples = 3<br/>value = [1, 2]<br/>class = positive>, fillcolor="#9ccef2"] ;
156 -> 158 ;
159 [label=<X<SUB>54</SUB> &le; 0.5<br/>entropy = 0.913<br/>samples = 70<br/>value = [47, 23]<br/>class = negative>, fillcolor="#f2bf9a"] ;
155 -> 159 ;
160 [label=<X<SUB>70</SUB> &le; 0.5<br/>entropy = 0.969<br/>samples = 53<br/>value = [32, 21]<br/>class = negative>, fillcolor="#f6d4bb"] ;
159 -> 160 ;
161 [label=<X<SUB>103</SUB> &le; 0.5<br/>entropy = 0.931<br/>samples = 49<br/>value = [32, 17]<br/>class = negative>, fillcolor="#f3c4a2"] ;
160 -> 161 ;
162 [label=<X<SUB>50</SUB> &le; 0.5<br/>entropy = 0.903<br/>samples = 47<br/>value = [32, 15]<br/>class = negative>, fillcolor="#f1bc96"] ;
161 -> 162 ;
163 [label=<entropy = 0.867<br/>samples = 45<br/>value = [32, 13]<br/>class = negative>, fillcolor="#f0b489"] ;
162 -> 163 ;
164 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = positive>, fillcolor="#399de5"] ;
162 -> 164 ;
165 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = positive>, fillcolor="#399de5"] ;
161 -> 165 ;
166 [label=<entropy = 0.0<br/>samples = 4<br/>value = [0, 4]<br/>class = positive>, fillcolor="#399de5"] ;
160 -> 166 ;
167 [label=<X<SUB>53</SUB> &le; 0.5<br/>entropy = 0.523<br/>samples = 17<br/>value = [15, 2]<br/>class = negative>, fillcolor="#e89253"] ;
159 -> 167 ;
168 [label=<X<SUB>43</SUB> &le; 0.5<br/>entropy = 0.337<br/>samples = 16<br/>value = [15, 1]<br/>class = negative>, fillcolor="#e78946"] ;
167 -> 168 ;
169 [label=<entropy = 0.0<br/>samples = 14<br/>value = [14, 0]<br/>class = negative>, fillcolor="#e58139"] ;
168 -> 169 ;
170 [label=<entropy = 1.0<br/>samples = 2<br/>value = [1, 1]<br/>class = negative>, fillcolor="#ffffff"] ;
168 -> 170 ;
171 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = positive>, fillcolor="#399de5"] ;
167 -> 171 ;
172 [label=<X<SUB>39</SUB> &le; 0.5<br/>entropy = 0.571<br/>samples = 333<br/>value = [288, 45]<br/>class = negative>, fillcolor="#e99558"] ;
4 -> 172 ;
173 [label=<X<SUB>38</SUB> &le; 0.5<br/>entropy = 0.527<br/>samples = 319<br/>value = [281, 38]<br/>class = negative>, fillcolor="#e99254"] ;
172 -> 173 ;
174 [label=<X<SUB>71</SUB> &le; 0.5<br/>entropy = 0.47<br/>samples = 299<br/>value = [269, 30]<br/>class = negative>, fillcolor="#e88f4f"] ;
173 -> 174 ;
175 [label=<X<SUB>90</SUB> &le; 0.5<br/>entropy = 0.529<br/>samples = 250<br/>value = [220, 30]<br/>class = negative>, fillcolor="#e99254"] ;
174 -> 175 ;
176 [label=<X<SUB>66</SUB> &le; 0.5<br/>entropy = 0.482<br/>samples = 240<br/>value = [215, 25]<br/>class = negative>, fillcolor="#e89050"] ;
175 -> 176 ;
177 [label=<X<SUB>91</SUB> &le; 0.5<br/>entropy = 0.578<br/>samples = 160<br/>value = [138, 22]<br/>class = negative>, fillcolor="#e99559"] ;
176 -> 177 ;
178 [label=<X<SUB>5</SUB> &le; 0.5<br/>entropy = 0.548<br/>samples = 158<br/>value = [138, 20]<br/>class = negative>, fillcolor="#e99356"] ;
177 -> 178 ;
179 [label=<X<SUB>60</SUB> &le; 0.5<br/>entropy = 0.657<br/>samples = 118<br/>value = [98, 20]<br/>class = negative>, fillcolor="#ea9b61"] ;
178 -> 179 ;
180 [label=<entropy = 0.699<br/>samples = 106<br/>value = [86, 20]<br/>class = negative>, fillcolor="#eb9e67"] ;
179 -> 180 ;
181 [label=<entropy = 0.0<br/>samples = 12<br/>value = [12, 0]<br/>class = negative>, fillcolor="#e58139"] ;
179 -> 181 ;
182 [label=<entropy = 0.0<br/>samples = 40<br/>value = [40, 0]<br/>class = negative>, fillcolor="#e58139"] ;
178 -> 182 ;
183 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = positive>, fillcolor="#399de5"] ;
177 -> 183 ;
184 [label=<X<SUB>42</SUB> &le; 0.5<br/>entropy = 0.231<br/>samples = 80<br/>value = [77, 3]<br/>class = negative>, fillcolor="#e68641"] ;
176 -> 184 ;
185 [label=<entropy = 0.17<br/>samples = 79<br/>value = [77, 2]<br/>class = negative>, fillcolor="#e6843e"] ;
184 -> 185 ;
186 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = positive>, fillcolor="#399de5"] ;
184 -> 186 ;
187 [label=<X<SUB>14</SUB> &le; 0.5<br/>entropy = 1.0<br/>samples = 10<br/>value = [5, 5]<br/>class = negative>, fillcolor="#ffffff"] ;
175 -> 187 ;
188 [label=<entropy = 0.863<br/>samples = 7<br/>value = [2, 5]<br/>class = positive>, fillcolor="#88c4ef"] ;
187 -> 188 ;
189 [label=<entropy = 0.0<br/>samples = 3<br/>value = [3, 0]<br/>class = negative>, fillcolor="#e58139"] ;
187 -> 189 ;
190 [label=<entropy = 0.0<br/>samples = 49<br/>value = [49, 0]<br/>class = negative>, fillcolor="#e58139"] ;
174 -> 190 ;
191 [label=<X<SUB>70</SUB> &le; 0.5<br/>entropy = 0.971<br/>samples = 20<br/>value = [12, 8]<br/>class = negative>, fillcolor="#f6d5bd"] ;
173 -> 191 ;
192 [label=<entropy = 0.874<br/>samples = 17<br/>value = [12, 5]<br/>class = negative>, fillcolor="#f0b58b"] ;
191 -> 192 ;
193 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = positive>, fillcolor="#399de5"] ;
191 -> 193 ;
194 [label=<X<SUB>2</SUB> &le; 0.5<br/>entropy = 1.0<br/>samples = 14<br/>value = [7, 7]<br/>class = negative>, fillcolor="#ffffff"] ;
172 -> 194 ;
195 [label=<X<SUB>94</SUB> &le; 0.5<br/>entropy = 0.881<br/>samples = 10<br/>value = [3, 7]<br/>class = positive>, fillcolor="#8ec7f0"] ;
194 -> 195 ;
196 [label=<entropy = 0.0<br/>samples = 6<br/>value = [0, 6]<br/>class = positive>, fillcolor="#399de5"] ;
195 -> 196 ;
197 [label=<X<SUB>37</SUB> &le; 0.5<br/>entropy = 0.811<br/>samples = 4<br/>value = [3, 1]<br/>class = negative>, fillcolor="#eeab7b"] ;
195 -> 197 ;
198 [label=<entropy = 0.0<br/>samples = 3<br/>value = [3, 0]<br/>class = negative>, fillcolor="#e58139"] ;
197 -> 198 ;
199 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = positive>, fillcolor="#399de5"] ;
197 -> 199 ;
200 [label=<entropy = 0.0<br/>samples = 4<br/>value = [4, 0]<br/>class = negative>, fillcolor="#e58139"] ;
194 -> 200 ;
201 [label=<X<SUB>58</SUB> &le; 0.5<br/>entropy = 0.79<br/>samples = 156<br/>value = [119, 37]<br/>class = negative>, fillcolor="#eda877"] ;
3 -> 201 ;
202 [label=<X<SUB>66</SUB> &le; 0.5<br/>entropy = 0.764<br/>samples = 153<br/>value = [119, 34]<br/>class = negative>, fillcolor="#eca572"] ;
201 -> 202 ;
203 [label=<X<SUB>22</SUB> &le; 0.5<br/>entropy = 0.894<br/>samples = 74<br/>value = [51, 23]<br/>class = negative>, fillcolor="#f1ba92"] ;
202 -> 203 ;
204 [label=<X<SUB>5</SUB> &le; 0.5<br/>entropy = 0.858<br/>samples = 71<br/>value = [51, 20]<br/>class = negative>, fillcolor="#efb287"] ;
203 -> 204 ;
205 [label=<X<SUB>17</SUB> &le; 0.5<br/>entropy = 0.947<br/>samples = 52<br/>value = [33, 19]<br/>class = negative>, fillcolor="#f4caab"] ;
204 -> 205 ;
206 [label=<entropy = 0.911<br/>samples = 49<br/>value = [33, 16]<br/>class = negative>, fillcolor="#f2be99"] ;
205 -> 206 ;
207 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = positive>, fillcolor="#399de5"] ;
205 -> 207 ;
208 [label=<X<SUB>43</SUB> &le; 0.5<br/>entropy = 0.297<br/>samples = 19<br/>value = [18, 1]<br/>class = negative>, fillcolor="#e68844"] ;
204 -> 208 ;
209 [label=<entropy = 0.0<br/>samples = 18<br/>value = [18, 0]<br/>class = negative>, fillcolor="#e58139"] ;
208 -> 209 ;
210 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = positive>, fillcolor="#399de5"] ;
208 -> 210 ;
211 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = positive>, fillcolor="#399de5"] ;
203 -> 211 ;
212 [label=<X<SUB>13</SUB> &le; 0.5<br/>entropy = 0.582<br/>samples = 79<br/>value = [68, 11]<br/>class = negative>, fillcolor="#e99559"] ;
202 -> 212 ;
213 [label=<X<SUB>0</SUB> &le; 0.5<br/>entropy = 0.46<br/>samples = 72<br/>value = [65, 7]<br/>class = negative>, fillcolor="#e88f4e"] ;
212 -> 213 ;
214 [label=<X<SUB>30</SUB> &le; 0.5<br/>entropy = 0.375<br/>samples = 69<br/>value = [64, 5]<br/>class = negative>, fillcolor="#e78b48"] ;
213 -> 214 ;
215 [label=<entropy = 0.222<br/>samples = 56<br/>value = [54, 2]<br/>class = negative>, fillcolor="#e68640"] ;
214 -> 215 ;
216 [label=<entropy = 0.779<br/>samples = 13<br/>value = [10, 3]<br/>class = negative>, fillcolor="#eda774"] ;
214 -> 216 ;
217 [label=<entropy = 0.918<br/>samples = 3<br/>value = [1, 2]<br/>class = positive>, fillcolor="#9ccef2"] ;
213 -> 217 ;
218 [label=<X<SUB>36</SUB> &le; 0.5<br/>entropy = 0.985<br/>samples = 7<br/>value = [3, 4]<br/>class = positive>, fillcolor="#cee6f8"] ;
212 -> 218 ;
219 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0]<br/>class = negative>, fillcolor="#e58139"] ;
218 -> 219 ;
220 [label=<entropy = 0.722<br/>samples = 5<br/>value = [1, 4]<br/>class = positive>, fillcolor="#6ab6ec"] ;
218 -> 220 ;
221 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = positive>, fillcolor="#399de5"] ;
201 -> 221 ;
222 [label=<X<SUB>6</SUB> &le; 0.5<br/>entropy = 0.845<br/>samples = 121<br/>value = [88, 33]<br/>class = negative>, fillcolor="#efb083"] ;
2 -> 222 ;
223 [label=<X<SUB>73</SUB> &le; 0.5<br/>entropy = 0.94<br/>samples = 84<br/>value = [54, 30]<br/>class = negative>, fillcolor="#f3c7a7"] ;
222 -> 223 ;
224 [label=<X<SUB>44</SUB> &le; 0.5<br/>entropy = 0.871<br/>samples = 72<br/>value = [51, 21]<br/>class = negative>, fillcolor="#f0b58b"] ;
223 -> 224 ;
225 [label=<X<SUB>12</SUB> &le; 0.5<br/>entropy = 0.908<br/>samples = 65<br/>value = [44, 21]<br/>class = negative>, fillcolor="#f1bd98"] ;
224 -> 225 ;
226 [label=<X<SUB>11</SUB> &le; 0.5<br/>entropy = 0.939<br/>samples = 59<br/>value = [38, 21]<br/>class = negative>, fillcolor="#f3c7a6"] ;
225 -> 226 ;
227 [label=<X<SUB>41</SUB> &le; 0.5<br/>entropy = 0.906<br/>samples = 56<br/>value = [38, 18]<br/>class = negative>, fillcolor="#f1bd97"] ;
226 -> 227 ;
228 [label=<X<SUB>55</SUB> &le; 0.5<br/>entropy = 0.86<br/>samples = 53<br/>value = [38, 15]<br/>class = negative>, fillcolor="#efb387"] ;
227 -> 228 ;
229 [label=<entropy = 0.712<br/>samples = 41<br/>value = [33, 8]<br/>class = negative>, fillcolor="#eba069"] ;
228 -> 229 ;
230 [label=<X<SUB>101</SUB> &le; 0.5<br/>entropy = 0.98<br/>samples = 12<br/>value = [5, 7]<br/>class = positive>, fillcolor="#c6e3f8"] ;
228 -> 230 ;
231 [label=<entropy = 0.863<br/>samples = 7<br/>value = [5, 2]<br/>class = negative>, fillcolor="#efb388"] ;
230 -> 231 ;
232 [label=<entropy = 0.0<br/>samples = 5<br/>value = [0, 5]<br/>class = positive>, fillcolor="#399de5"] ;
230 -> 232 ;
233 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = positive>, fillcolor="#399de5"] ;
227 -> 233 ;
234 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = positive>, fillcolor="#399de5"] ;
226 -> 234 ;
235 [label=<entropy = 0.0<br/>samples = 6<br/>value = [6, 0]<br/>class = negative>, fillcolor="#e58139"] ;
225 -> 235 ;
236 [label=<entropy = 0.0<br/>samples = 7<br/>value = [7, 0]<br/>class = negative>, fillcolor="#e58139"] ;
224 -> 236 ;
237 [label=<entropy = 0.811<br/>samples = 12<br/>value = [3, 9]<br/>class = positive>, fillcolor="#7bbeee"] ;
223 -> 237 ;
238 [label=<X<SUB>58</SUB> &le; 0.5<br/>entropy = 0.406<br/>samples = 37<br/>value = [34, 3]<br/>class = negative>, fillcolor="#e78c4a"] ;
222 -> 238 ;
239 [label=<X<SUB>86</SUB> &le; 0.5<br/>entropy = 0.187<br/>samples = 35<br/>value = [34, 1]<br/>class = negative>, fillcolor="#e6853f"] ;
238 -> 239 ;
240 [label=<entropy = 0.0<br/>samples = 34<br/>value = [34, 0]<br/>class = negative>, fillcolor="#e58139"] ;
239 -> 240 ;
241 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = positive>, fillcolor="#399de5"] ;
239 -> 241 ;
242 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = positive>, fillcolor="#399de5"] ;
238 -> 242 ;
243 [label=<X<SUB>0</SUB> &le; 0.5<br/>entropy = 0.858<br/>samples = 202<br/>value = [145, 57]<br/>class = negative>, fillcolor="#efb387"] ;
1 -> 243 ;
244 [label=<X<SUB>59</SUB> &le; 0.5<br/>entropy = 0.674<br/>samples = 158<br/>value = [130, 28]<br/>class = negative>, fillcolor="#eb9c64"] ;
243 -> 244 ;
245 [label=<X<SUB>76</SUB> &le; 0.5<br/>entropy = 0.439<br/>samples = 132<br/>value = [120, 12]<br/>class = negative>, fillcolor="#e88e4d"] ;
244 -> 245 ;
246 [label=<X<SUB>27</SUB> &le; 0.5<br/>entropy = 0.391<br/>samples = 130<br/>value = [120, 10]<br/>class = negative>, fillcolor="#e78c49"] ;
245 -> 246 ;
247 [label=<X<SUB>65</SUB> &le; 0.5<br/>entropy = 0.365<br/>samples = 129<br/>value = [120, 9]<br/>class = negative>, fillcolor="#e78a48"] ;
246 -> 247 ;
248 [label=<X<SUB>5</SUB> &le; 0.5<br/>entropy = 0.476<br/>samples = 88<br/>value = [79, 9]<br/>class = negative>, fillcolor="#e88f50"] ;
247 -> 248 ;
249 [label=<X<SUB>11</SUB> &le; 0.5<br/>entropy = 0.679<br/>samples = 39<br/>value = [32, 7]<br/>class = negative>, fillcolor="#eb9d64"] ;
248 -> 249 ;
250 [label=<entropy = 0.571<br/>samples = 37<br/>value = [32, 5]<br/>class = negative>, fillcolor="#e99558"] ;
249 -> 250 ;
251 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = positive>, fillcolor="#399de5"] ;
249 -> 251 ;
252 [label=<X<SUB>42</SUB> &le; 0.5<br/>entropy = 0.246<br/>samples = 49<br/>value = [47, 2]<br/>class = negative>, fillcolor="#e68641"] ;
248 -> 252 ;
253 [label=<X<SUB>28</SUB> &le; 0.5<br/>entropy = 0.146<br/>samples = 48<br/>value = [47, 1]<br/>class = negative>, fillcolor="#e6843d"] ;
252 -> 253 ;
254 [label=<entropy = 0.0<br/>samples = 46<br/>value = [46, 0]<br/>class = negative>, fillcolor="#e58139"] ;
253 -> 254 ;
255 [label=<entropy = 1.0<br/>samples = 2<br/>value = [1, 1]<br/>class = negative>, fillcolor="#ffffff"] ;
253 -> 255 ;
256 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = positive>, fillcolor="#399de5"] ;
252 -> 256 ;
257 [label=<entropy = 0.0<br/>samples = 41<br/>value = [41, 0]<br/>class = negative>, fillcolor="#e58139"] ;
247 -> 257 ;
258 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = positive>, fillcolor="#399de5"] ;
246 -> 258 ;
259 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = positive>, fillcolor="#399de5"] ;
245 -> 259 ;
260 [label=<X<SUB>27</SUB> &le; 0.5<br/>entropy = 0.961<br/>samples = 26<br/>value = [10, 16]<br/>class = positive>, fillcolor="#b5daf5"] ;
244 -> 260 ;
261 [label=<X<SUB>101</SUB> &le; 0.5<br/>entropy = 0.503<br/>samples = 18<br/>value = [2, 16]<br/>class = positive>, fillcolor="#52a9e8"] ;
260 -> 261 ;
262 [label=<entropy = 0.323<br/>samples = 17<br/>value = [1, 16]<br/>class = positive>, fillcolor="#45a3e7"] ;
261 -> 262 ;
263 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = negative>, fillcolor="#e58139"] ;
261 -> 263 ;
264 [label=<entropy = 0.0<br/>samples = 8<br/>value = [8, 0]<br/>class = negative>, fillcolor="#e58139"] ;
260 -> 264 ;
265 [label=<X<SUB>10</SUB> &le; 0.5<br/>entropy = 0.926<br/>samples = 44<br/>value = [15, 29]<br/>class = positive>, fillcolor="#9fd0f2"] ;
243 -> 265 ;
266 [label=<X<SUB>11</SUB> &le; 0.5<br/>entropy = 0.849<br/>samples = 40<br/>value = [11, 29]<br/>class = positive>, fillcolor="#84c2ef"] ;
265 -> 266 ;
267 [label=<entropy = 0.0<br/>samples = 4<br/>value = [4, 0]<br/>class = negative>, fillcolor="#e58139"] ;
266 -> 267 ;
268 [label=<entropy = 0.711<br/>samples = 36<br/>value = [7, 29]<br/>class = positive>, fillcolor="#69b5eb"] ;
266 -> 268 ;
269 [label=<entropy = 0.0<br/>samples = 4<br/>value = [4, 0]<br/>class = negative>, fillcolor="#e58139"] ;
265 -> 269 ;
270 [label=<X<SUB>94</SUB> &le; 0.5<br/>entropy = 0.948<br/>samples = 289<br/>value = [183, 106]<br/>class = negative>, fillcolor="#f4caac"] ;
0 -> 270 [labeldistance=2.5, labelangle=-45, headlabel="False"] ;
271 [label=<X<SUB>11</SUB> &le; 0.5<br/>entropy = 0.994<br/>samples = 213<br/>value = [116, 97]<br/>class = negative>, fillcolor="#fbeadf"] ;
270 -> 271 ;
272 [label=<X<SUB>52</SUB> &le; 0.5<br/>entropy = 0.985<br/>samples = 203<br/>value = [116, 87]<br/>class = negative>, fillcolor="#f8e0ce"] ;
271 -> 272 ;
273 [label=<X<SUB>87</SUB> &le; 0.5<br/>entropy = 0.843<br/>samples = 96<br/>value = [70, 26]<br/>class = negative>, fillcolor="#efb083"] ;
272 -> 273 ;
274 [label=<X<SUB>101</SUB> &le; 0.5<br/>entropy = 0.701<br/>samples = 79<br/>value = [64, 15]<br/>class = negative>, fillcolor="#eb9f67"] ;
273 -> 274 ;
275 [label=<X<SUB>66</SUB> &le; 0.5<br/>entropy = 0.497<br/>samples = 55<br/>value = [49, 6]<br/>class = negative>, fillcolor="#e89051"] ;
274 -> 275 ;
276 [label=<entropy = 0.0<br/>samples = 23<br/>value = [23, 0]<br/>class = negative>, fillcolor="#e58139"] ;
275 -> 276 ;
277 [label=<entropy = 0.696<br/>samples = 32<br/>value = [26, 6]<br/>class = negative>, fillcolor="#eb9e67"] ;
275 -> 277 ;
278 [label=<X<SUB>82</SUB> &le; 0.5<br/>entropy = 0.954<br/>samples = 24<br/>value = [15, 9]<br/>class = negative>, fillcolor="#f5cdb0"] ;
274 -> 278 ;
279 [label=<X<SUB>97</SUB> &le; 0.5<br/>entropy = 0.863<br/>samples = 21<br/>value = [15, 6]<br/>class = negative>, fillcolor="#efb388"] ;
278 -> 279 ;
280 [label=<entropy = 0.742<br/>samples = 19<br/>value = [15, 4]<br/>class = negative>, fillcolor="#eca36e"] ;
279 -> 280 ;
281 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = positive>, fillcolor="#399de5"] ;
279 -> 281 ;
282 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = positive>, fillcolor="#399de5"] ;
278 -> 282 ;
283 [label=<X<SUB>6</SUB> &le; 0.5<br/>entropy = 0.937<br/>samples = 17<br/>value = [6, 11]<br/>class = positive>, fillcolor="#a5d2f3"] ;
273 -> 283 ;
284 [label=<entropy = 0.0<br/>samples = 10<br/>value = [0, 10]<br/>class = positive>, fillcolor="#399de5"] ;
283 -> 284 ;
285 [label=<entropy = 0.592<br/>samples = 7<br/>value = [6, 1]<br/>class = negative>, fillcolor="#e9965a"] ;
283 -> 285 ;
286 [label=<X<SUB>22</SUB> &le; 0.5<br/>entropy = 0.986<br/>samples = 107<br/>value = [46, 61]<br/>class = positive>, fillcolor="#cee7f9"] ;
272 -> 286 ;
287 [label=<X<SUB>80</SUB> &le; 0.5<br/>entropy = 0.993<br/>samples = 102<br/>value = [46, 56]<br/>class = positive>, fillcolor="#dceefa"] ;
286 -> 287 ;
288 [label=<entropy = 0.997<br/>samples = 98<br/>value = [46, 52]<br/>class = positive>, fillcolor="#e8f4fc"] ;
287 -> 288 ;
289 [label=<entropy = 0.0<br/>samples = 4<br/>value = [0, 4]<br/>class = positive>, fillcolor="#399de5"] ;
287 -> 289 ;
290 [label=<entropy = 0.0<br/>samples = 5<br/>value = [0, 5]<br/>class = positive>, fillcolor="#399de5"] ;
286 -> 290 ;
291 [label=<entropy = 0.0<br/>samples = 10<br/>value = [0, 10]<br/>class = positive>, fillcolor="#399de5"] ;
271 -> 291 ;
292 [label=<X<SUB>50</SUB> &le; 0.5<br/>entropy = 0.525<br/>samples = 76<br/>value = [67, 9]<br/>class = negative>, fillcolor="#e89254"] ;
270 -> 292 ;
293 [label=<X<SUB>93</SUB> &le; 0.5<br/>entropy = 0.375<br/>samples = 69<br/>value = [64, 5]<br/>class = negative>, fillcolor="#e78b48"] ;
292 -> 293 ;
294 [label=<X<SUB>97</SUB> &le; 0.5<br/>entropy = 0.27<br/>samples = 65<br/>value = [62, 3]<br/>class = negative>, fillcolor="#e68743"] ;
293 -> 294 ;
295 [label=<entropy = 0.0<br/>samples = 49<br/>value = [49, 0]<br/>class = negative>, fillcolor="#e58139"] ;
294 -> 295 ;
296 [label=<X<SUB>55</SUB> &le; 0.5<br/>entropy = 0.696<br/>samples = 16<br/>value = [13, 3]<br/>class = negative>, fillcolor="#eb9e67"] ;
294 -> 296 ;
297 [label=<entropy = 0.0<br/>samples = 10<br/>value = [10, 0]<br/>class = negative>, fillcolor="#e58139"] ;
296 -> 297 ;
298 [label=<entropy = 1.0<br/>samples = 6<br/>value = [3, 3]<br/>class = negative>, fillcolor="#ffffff"] ;
296 -> 298 ;
299 [label=<X<SUB>60</SUB> &le; 0.5<br/>entropy = 1.0<br/>samples = 4<br/>value = [2, 2]<br/>class = negative>, fillcolor="#ffffff"] ;
293 -> 299 ;
300 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = positive>, fillcolor="#399de5"] ;
299 -> 300 ;
301 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0]<br/>class = negative>, fillcolor="#e58139"] ;
299 -> 301 ;
302 [label=<entropy = 0.985<br/>samples = 7<br/>value = [3, 4]<br/>class = positive>, fillcolor="#cee6f8"] ;
292 -> 302 ;
}