digraph Tree {
node [shape=box, style="filled, rounded", color="black", fontname=helvetica] ;
edge [fontname=helvetica] ;
0 [label=<X<SUB>8</SUB> &le; 0.5<br/>entropy = 0.411<br/>samples = 6294<br/>value = [5775, 519]<br/>class = negative>, fillcolor="#e78c4b"] ;
1 [label=<X<SUB>88</SUB> &le; 0.5<br/>entropy = 0.36<br/>samples = 5979<br/>value = [5570, 409]<br/>class = negative>, fillcolor="#e78a48"] ;
0 -> 1 [labeldistance=2.5, labelangle=45, headlabel="True"] ;
2 [label=<X<SUB>180</SUB> &le; 0.5<br/>entropy = 0.327<br/>samples = 5756<br/>value = [5411, 345]<br/>class = negative>, fillcolor="#e78946"] ;
1 -> 2 ;
3 [label=<X<SUB>130</SUB> &le; 0.5<br/>entropy = 0.301<br/>samples = 5487<br/>value = [5194, 293]<br/>class = negative>, fillcolor="#e68844"] ;
2 -> 3 ;
4 [label=<X<SUB>23</SUB> &le; 0.5<br/>entropy = 0.278<br/>samples = 5345<br/>value = [5088, 257]<br/>class = negative>, fillcolor="#e68743"] ;
3 -> 4 ;
5 [label=<X<SUB>66</SUB> &le; 0.5<br/>entropy = 0.241<br/>samples = 4943<br/>value = [4747, 196]<br/>class = negative>, fillcolor="#e68641"] ;
4 -> 5 ;
6 [label=<X<SUB>134</SUB> &le; 0.5<br/>entropy = 0.223<br/>samples = 4818<br/>value = [4645, 173]<br/>class = negative>, fillcolor="#e68640"] ;
5 -> 6 ;
7 [label=<X<SUB>181</SUB> &le; 0.5<br/>entropy = 0.211<br/>samples = 4763<br/>value = [4604, 159]<br/>class = negative>, fillcolor="#e68540"] ;
6 -> 7 ;
8 [label=<X<SUB>89</SUB> &le; 0.5<br/>entropy = 0.189<br/>samples = 4485<br/>value = [4355, 130]<br/>class = negative>, fillcolor="#e6853f"] ;
7 -> 8 ;
9 [label=<X<SUB>163</SUB> &le; 0.5<br/>entropy = 0.174<br/>samples = 4306<br/>value = [4194, 112]<br/>class = negative>, fillcolor="#e6843e"] ;
8 -> 9 ;
10 [label=<entropy = 0.205<br/>samples = 2889<br/>value = [2796, 93]<br/>class = negative>, fillcolor="#e68540"] ;
9 -> 10 ;
11 [label=<entropy = 0.103<br/>samples = 1417<br/>value = [1398, 19]<br/>class = negative>, fillcolor="#e5833c"] ;
9 -> 11 ;
12 [label=<X<SUB>21</SUB> &le; 0.5<br/>entropy = 0.471<br/>samples = 179<br/>value = [161, 18]<br/>class = negative>, fillcolor="#e88f4f"] ;
8 -> 12 ;
13 [label=<entropy = 0.385<br/>samples = 173<br/>value = [160, 13]<br/>class = negative>, fillcolor="#e78b49"] ;
12 -> 13 ;
14 [label=<entropy = 0.65<br/>samples = 6<br/>value = [1, 5]<br/>class = positive>, fillcolor="#61b1ea"] ;
12 -> 14 ;
15 [label=<X<SUB>155</SUB> &le; 0.5<br/>entropy = 0.483<br/>samples = 278<br/>value = [249, 29]<br/>class = negative>, fillcolor="#e89050"] ;
7 -> 15 ;
16 [label=<X<SUB>159</SUB> &le; 0.5<br/>entropy = 0.422<br/>samples = 268<br/>value = [245, 23]<br/>class = negative>, fillcolor="#e78d4c"] ;
15 -> 16 ;
17 [label=<entropy = 0.505<br/>samples = 206<br/>value = [183, 23]<br/>class = negative>, fillcolor="#e89152"] ;
16 -> 17 ;
18 [label=<entropy = 0.0<br/>samples = 62<br/>value = [62, 0]<br/>class = negative>, fillcolor="#e58139"] ;
16 -> 18 ;
19 [label=<X<SUB>65</SUB> &le; 0.5<br/>entropy = 0.971<br/>samples = 10<br/>value = [4, 6]<br/>class = positive>, fillcolor="#bddef6"] ;
15 -> 19 ;
20 [label=<entropy = 0.722<br/>samples = 5<br/>value = [4, 1]<br/>class = negative>, fillcolor="#eca06a"] ;
19 -> 20 ;
21 [label=<entropy = 0.0<br/>samples = 5<br/>value = [0, 5]<br/>class = positive>, fillcolor="#399de5"] ;
19 -> 21 ;
22 [label=<X<SUB>120</SUB> &le; 0.5<br/>entropy = 0.818<br/>samples = 55<br/>value = [41, 14]<br/>class = negative>, fillcolor="#eeac7d"] ;
6 -> 22 ;
23 [label=<X<SUB>3</SUB> &le; 0.5<br/>entropy = 0.714<br/>samples = 51<br/>value = [41, 10]<br/>class = negative>, fillcolor="#eba069"] ;
22 -> 23 ;
24 [label=<X<SUB>157</SUB> &le; 0.5<br/>entropy = 0.559<br/>samples = 46<br/>value = [40, 6]<br/>class = negative>, fillcolor="#e99457"] ;
23 -> 24 ;
25 [label=<entropy = 0.736<br/>samples = 29<br/>value = [23, 6]<br/>class = negative>, fillcolor="#eca26d"] ;
24 -> 25 ;
26 [label=<entropy = 0.0<br/>samples = 17<br/>value = [17, 0]<br/>class = negative>, fillcolor="#e58139"] ;
24 -> 26 ;
27 [label=<X<SUB>124</SUB> &le; 0.5<br/>entropy = 0.722<br/>samples = 5<br/>value = [1, 4]<br/>class = positive>, fillcolor="#6ab6ec"] ;
23 -> 27 ;
28 [label=<entropy = 0.0<br/>samples = 4<br/>value = [0, 4]<br/>class = positive>, fillcolor="#399de5"] ;
27 -> 28 ;
29 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = negative>, fillcolor="#e58139"] ;
27 -> 29 ;
30 [label=<entropy = 0.0<br/>samples = 4<br/>value = [0, 4]<br/>class = positive>, fillcolor="#399de5"] ;
22 -> 30 ;
31 [label=<X<SUB>133</SUB> &le; 0.5<br/>entropy = 0.689<br/>samples = 125<br/>value = [102, 23]<br/>class = negative>, fillcolor="#eb9d66"] ;
5 -> 31 ;
32 [label=<X<SUB>164</SUB> &le; 0.5<br/>entropy = 0.439<br/>samples = 110<br/>value = [100, 10]<br/>class = negative>, fillcolor="#e88e4d"] ;
31 -> 32 ;
33 [label=<X<SUB>143</SUB> &le; 0.5<br/>entropy = 0.381<br/>samples = 108<br/>value = [100, 8]<br/>class = negative>, fillcolor="#e78b49"] ;
32 -> 33 ;
34 [label=<X<SUB>80</SUB> &le; 0.5<br/>entropy = 0.323<br/>samples = 102<br/>value = [96, 6]<br/>class = negative>, fillcolor="#e78945"] ;
33 -> 34 ;
35 [label=<entropy = 0.252<br/>samples = 95<br/>value = [91, 4]<br/>class = negative>, fillcolor="#e68742"] ;
34 -> 35 ;
36 [label=<entropy = 0.863<br/>samples = 7<br/>value = [5, 2]<br/>class = negative>, fillcolor="#efb388"] ;
34 -> 36 ;
37 [label=<X<SUB>67</SUB> &le; 0.5<br/>entropy = 0.918<br/>samples = 6<br/>value = [4, 2]<br/>class = negative>, fillcolor="#f2c09c"] ;
33 -> 37 ;
38 [label=<entropy = 0.722<br/>samples = 5<br/>value = [4, 1]<br/>class = negative>, fillcolor="#eca06a"] ;
37 -> 38 ;
39 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = positive>, fillcolor="#399de5"] ;
37 -> 39 ;
40 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = positive>, fillcolor="#399de5"] ;
32 -> 40 ;
41 [label=<X<SUB>131</SUB> &le; 0.5<br/>entropy = 0.567<br/>samples = 15<br/>value = [2, 13]<br/>class = positive>, fillcolor="#57ace9"] ;
31 -> 41 ;
42 [label=<X<SUB>89</SUB> &le; 0.5<br/>entropy = 0.371<br/>samples = 14<br/>value = [1, 13]<br/>class = positive>, fillcolor="#48a5e7"] ;
41 -> 42 ;
43 [label=<entropy = 0.0<br/>samples = 10<br/>value = [0, 10]<br/>class = positive>, fillcolor="#399de5"] ;
42 -> 43 ;
44 [label=<X<SUB>87</SUB> &le; 0.5<br/>entropy = 0.811<br/>samples = 4<br/>value = [1, 3]<br/>class = positive>, fillcolor="#7bbeee"] ;
42 -> 44 ;
45 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = positive>, fillcolor="#399de5"] ;
44 -> 45 ;
46 [label=<entropy = 1.0<br/>samples = 2<br/>value = [1, 1]<br/>class = negative>, fillcolor="#ffffff"] ;
44 -> 46 ;
47 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = negative>, fillcolor="#e58139"] ;
41 -> 47 ;
48 [label=<X<SUB>63</SUB> &le; 0.5<br/>entropy = 0.614<br/>samples = 402<br/>value = [341, 61]<br/>class = negative>, fillcolor="#ea985c"] ;
4 -> 48 ;
49 [label=<X<SUB>3</SUB> &le; 0.5<br/>entropy = 0.702<br/>samples = 310<br/>value = [251, 59]<br/>class = negative>, fillcolor="#eb9f68"] ;
48 -> 49 ;
50 [label=<X<SUB>29</SUB> &le; 0.5<br/>entropy = 0.655<br/>samples = 296<br/>value = [246, 50]<br/>class = negative>, fillcolor="#ea9b61"] ;
49 -> 50 ;
51 [label=<X<SUB>31</SUB> &le; 0.5<br/>entropy = 0.735<br/>samples = 237<br/>value = [188, 49]<br/>class = negative>, fillcolor="#eca26d"] ;
50 -> 51 ;
52 [label=<X<SUB>173</SUB> &le; 0.5<br/>entropy = 0.702<br/>samples = 231<br/>value = [187, 44]<br/>class = negative>, fillcolor="#eb9f68"] ;
51 -> 52 ;
53 [label=<entropy = 0.68<br/>samples = 228<br/>value = [187, 41]<br/>class = negative>, fillcolor="#eb9d64"] ;
52 -> 53 ;
54 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = positive>, fillcolor="#399de5"] ;
52 -> 54 ;
55 [label=<X<SUB>75</SUB> &le; 0.5<br/>entropy = 0.65<br/>samples = 6<br/>value = [1, 5]<br/>class = positive>, fillcolor="#61b1ea"] ;
51 -> 55 ;
56 [label=<entropy = 0.0<br/>samples = 5<br/>value = [0, 5]<br/>class = positive>, fillcolor="#399de5"] ;
55 -> 56 ;
57 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = negative>, fillcolor="#e58139"] ;
55 -> 57 ;
58 [label=<X<SUB>171</SUB> &le; 0.5<br/>entropy = 0.124<br/>samples = 59<br/>value = [58, 1]<br/>class = negative>, fillcolor="#e5833c"] ;
50 -> 58 ;
59 [label=<entropy = 0.0<br/>samples = 52<br/>value = [52, 0]<br/>class = negative>, fillcolor="#e58139"] ;
58 -> 59 ;
60 [label=<X<SUB>75</SUB> &le; 0.5<br/>entropy = 0.592<br/>samples = 7<br/>value = [6, 1]<br/>class = negative>, fillcolor="#e9965a"] ;
58 -> 60 ;
61 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = positive>, fillcolor="#399de5"] ;
60 -> 61 ;
62 [label=<entropy = 0.0<br/>samples = 6<br/>value = [6, 0]<br/>class = negative>, fillcolor="#e58139"] ;
60 -> 62 ;
63 [label=<X<SUB>29</SUB> &le; 0.5<br/>entropy = 0.94<br/>samples = 14<br/>value = [5, 9]<br/>class = positive>, fillcolor="#a7d3f3"] ;
49 -> 63 ;
64 [label=<X<SUB>167</SUB> &le; 0.5<br/>entropy = 0.722<br/>samples = 5<br/>value = [4, 1]<br/>class = negative>, fillcolor="#eca06a"] ;
63 -> 64 ;
65 [label=<entropy = 0.0<br/>samples = 4<br/>value = [4, 0]<br/>class = negative>, fillcolor="#e58139"] ;
64 -> 65 ;
66 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = positive>, fillcolor="#399de5"] ;
64 -> 66 ;
67 [label=<X<SUB>131</SUB> &le; 0.5<br/>entropy = 0.503<br/>samples = 9<br/>value = [1, 8]<br/>class = positive>, fillcolor="#52a9e8"] ;
63 -> 67 ;
68 [label=<entropy = 0.0<br/>samples = 8<br/>value = [0, 8]<br/>class = positive>, fillcolor="#399de5"] ;
67 -> 68 ;
69 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = negative>, fillcolor="#e58139"] ;
67 -> 69 ;
70 [label=<X<SUB>181</SUB> &le; 0.5<br/>entropy = 0.151<br/>samples = 92<br/>value = [90, 2]<br/>class = negative>, fillcolor="#e6843d"] ;
48 -> 70 ;
71 [label=<entropy = 0.0<br/>samples = 83<br/>value = [83, 0]<br/>class = negative>, fillcolor="#e58139"] ;
70 -> 71 ;
72 [label=<X<SUB>152</SUB> &le; 0.5<br/>entropy = 0.764<br/>samples = 9<br/>value = [7, 2]<br/>class = negative>, fillcolor="#eca572"] ;
70 -> 72 ;
73 [label=<entropy = 0.0<br/>samples = 6<br/>value = [6, 0]<br/>class = negative>, fillcolor="#e58139"] ;
72 -> 73 ;
74 [label=<X<SUB>163</SUB> &le; 0.5<br/>entropy = 0.918<br/>samples = 3<br/>value = [1, 2]<br/>class = positive>, fillcolor="#9ccef2"] ;
72 -> 74 ;
75 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = positive>, fillcolor="#399de5"] ;
74 -> 75 ;
76 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = negative>, fillcolor="#e58139"] ;
74 -> 76 ;
77 [label=<X<SUB>171</SUB> &le; 0.5<br/>entropy = 0.817<br/>samples = 142<br/>value = [106, 36]<br/>class = negative>, fillcolor="#eeac7c"] ;
3 -> 77 ;
78 [label=<X<SUB>3</SUB> &le; 0.5<br/>entropy = 0.4<br/>samples = 63<br/>value = [58, 5]<br/>class = negative>, fillcolor="#e78c4a"] ;
77 -> 78 ;
79 [label=<X<SUB>86</SUB> &le; 0.5<br/>entropy = 0.214<br/>samples = 59<br/>value = [57, 2]<br/>class = negative>, fillcolor="#e68540"] ;
78 -> 79 ;
80 [label=<X<SUB>81</SUB> &le; 0.5<br/>entropy = 0.126<br/>samples = 58<br/>value = [57, 1]<br/>class = negative>, fillcolor="#e5833c"] ;
79 -> 80 ;
81 [label=<entropy = 0.0<br/>samples = 53<br/>value = [53, 0]<br/>class = negative>, fillcolor="#e58139"] ;
80 -> 81 ;
82 [label=<X<SUB>36</SUB> &le; 0.5<br/>entropy = 0.722<br/>samples = 5<br/>value = [4, 1]<br/>class = negative>, fillcolor="#eca06a"] ;
80 -> 82 ;
83 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = positive>, fillcolor="#399de5"] ;
82 -> 83 ;
84 [label=<entropy = 0.0<br/>samples = 4<br/>value = [4, 0]<br/>class = negative>, fillcolor="#e58139"] ;
82 -> 84 ;
85 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = positive>, fillcolor="#399de5"] ;
79 -> 85 ;
86 [label=<X<SUB>116</SUB> &le; 0.5<br/>entropy = 0.811<br/>samples = 4<br/>value = [1, 3]<br/>class = positive>, fillcolor="#7bbeee"] ;
78 -> 86 ;
87 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = positive>, fillcolor="#399de5"] ;
86 -> 87 ;
88 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = negative>, fillcolor="#e58139"] ;
86 -> 88 ;
89 [label=<X<SUB>182</SUB> &le; 0.5<br/>entropy = 0.966<br/>samples = 79<br/>value = [48, 31]<br/>class = negative>, fillcolor="#f6d2b9"] ;
77 -> 89 ;
90 [label=<X<SUB>60</SUB> &le; 0.5<br/>entropy = 0.935<br/>samples = 74<br/>value = [48, 26]<br/>class = negative>, fillcolor="#f3c5a4"] ;
89 -> 90 ;
91 [label=<X<SUB>10</SUB> &le; 0.5<br/>entropy = 0.892<br/>samples = 68<br/>value = [47, 21]<br/>class = negative>, fillcolor="#f1b991"] ;
90 -> 91 ;
92 [label=<X<SUB>87</SUB> &le; 0.5<br/>entropy = 0.949<br/>samples = 57<br/>value = [36, 21]<br/>class = negative>, fillcolor="#f4caac"] ;
91 -> 92 ;
93 [label=<X<SUB>166</SUB> &le; 0.5<br/>entropy = 0.918<br/>samples = 54<br/>value = [36, 18]<br/>class = negative>, fillcolor="#f2c09c"] ;
92 -> 93 ;
94 [label=<entropy = 0.89<br/>samples = 52<br/>value = [36, 16]<br/>class = negative>, fillcolor="#f1b991"] ;
93 -> 94 ;
95 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = positive>, fillcolor="#399de5"] ;
93 -> 95 ;
96 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = positive>, fillcolor="#399de5"] ;
92 -> 96 ;
97 [label=<entropy = 0.0<br/>samples = 11<br/>value = [11, 0]<br/>class = negative>, fillcolor="#e58139"] ;
91 -> 97 ;
98 [label=<X<SUB>121</SUB> &le; 0.5<br/>entropy = 0.65<br/>samples = 6<br/>value = [1, 5]<br/>class = positive>, fillcolor="#61b1ea"] ;
90 -> 98 ;
99 [label=<entropy = 0.0<br/>samples = 5<br/>value = [0, 5]<br/>class = positive>, fillcolor="#399de5"] ;
98 -> 99 ;
100 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = negative>, fillcolor="#e58139"] ;
98 -> 100 ;
101 [label=<entropy = 0.0<br/>samples = 5<br/>value = [0, 5]<br/>class = positive>, fillcolor="#399de5"] ;
89 -> 101 ;
102 [label=<X<SUB>116</SUB> &le; 0.5<br/>entropy = 0.708<br/>samples = 269<br/>value = [217, 52]<br/>class = negative>, fillcolor="#eb9f68"] ;
2 -> 102 ;
103 [label=<X<SUB>103</SUB> &le; 0.5<br/>entropy = 0.778<br/>samples = 222<br/>value = [171, 51]<br/>class = negative>, fillcolor="#eda774"] ;
102 -> 103 ;
104 [label=<X<SUB>137</SUB> &le; 0.5<br/>entropy = 0.738<br/>samples = 216<br/>value = [171, 45]<br/>class = negative>, fillcolor="#eca26d"] ;
103 -> 104 ;
105 [label=<X<SUB>27</SUB> &le; 0.5<br/>entropy = 0.807<br/>samples = 182<br/>value = [137, 45]<br/>class = negative>, fillcolor="#eeaa7a"] ;
104 -> 105 ;
106 [label=<X<SUB>63</SUB> &le; 0.5<br/>entropy = 0.714<br/>samples = 158<br/>value = [127, 31]<br/>class = negative>, fillcolor="#eba069"] ;
105 -> 106 ;
107 [label=<X<SUB>22</SUB> &le; 0.5<br/>entropy = 0.766<br/>samples = 139<br/>value = [108, 31]<br/>class = negative>, fillcolor="#eca572"] ;
106 -> 107 ;
108 [label=<X<SUB>93</SUB> &le; 0.5<br/>entropy = 0.734<br/>samples = 136<br/>value = [108, 28]<br/>class = negative>, fillcolor="#eca26c"] ;
107 -> 108 ;
109 [label=<entropy = 0.791<br/>samples = 118<br/>value = [90, 28]<br/>class = negative>, fillcolor="#eda877"] ;
108 -> 109 ;
110 [label=<entropy = 0.0<br/>samples = 18<br/>value = [18, 0]<br/>class = negative>, fillcolor="#e58139"] ;
108 -> 110 ;
111 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = positive>, fillcolor="#399de5"] ;
107 -> 111 ;
112 [label=<entropy = 0.0<br/>samples = 19<br/>value = [19, 0]<br/>class = negative>, fillcolor="#e58139"] ;
106 -> 112 ;
113 [label=<X<SUB>62</SUB> &le; 0.5<br/>entropy = 0.98<br/>samples = 24<br/>value = [10, 14]<br/>class = positive>, fillcolor="#c6e3f8"] ;
105 -> 113 ;
114 [label=<X<SUB>59</SUB> &le; 0.5<br/>entropy = 0.918<br/>samples = 21<br/>value = [7, 14]<br/>class = positive>, fillcolor="#9ccef2"] ;
113 -> 114 ;
115 [label=<X<SUB>10</SUB> &le; 0.5<br/>entropy = 0.964<br/>samples = 18<br/>value = [7, 11]<br/>class = positive>, fillcolor="#b7dbf6"] ;
114 -> 115 ;
116 [label=<entropy = 0.896<br/>samples = 16<br/>value = [5, 11]<br/>class = positive>, fillcolor="#93caf1"] ;
115 -> 116 ;
117 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0]<br/>class = negative>, fillcolor="#e58139"] ;
115 -> 117 ;
118 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = positive>, fillcolor="#399de5"] ;
114 -> 118 ;
119 [label=<entropy = 0.0<br/>samples = 3<br/>value = [3, 0]<br/>class = negative>, fillcolor="#e58139"] ;
113 -> 119 ;
120 [label=<entropy = 0.0<br/>samples = 34<br/>value = [34, 0]<br/>class = negative>, fillcolor="#e58139"] ;
104 -> 120 ;
121 [label=<entropy = 0.0<br/>samples = 6<br/>value = [0, 6]<br/>class = positive>, fillcolor="#399de5"] ;
103 -> 121 ;
122 [label=<X<SUB>166</SUB> &le; 0.5<br/>entropy = 0.149<br/>samples = 47<br/>value = [46, 1]<br/>class = negative>, fillcolor="#e6843d"] ;
102 -> 122 ;
123 [label=<entropy = 0.0<br/>samples = 44<br/>value = [44, 0]<br/>class = negative>, fillcolor="#e58139"] ;
122 -> 123 ;
124 [label=<X<SUB>62</SUB> &le; 0.5<br/>entropy = 0.918<br/>samples = 3<br/>value = [2, 1]<br/>class = negative>, fillcolor="#f2c09c"] ;
122 -> 124 ;
125 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0]<br/>class = negative>, fillcolor="#e58139"] ;
124 -> 125 ;
126 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = positive>, fillcolor="#399de5"] ;
124 -> 126 ;
127 [label=<X<SUB>14</SUB> &le; 0.5<br/>entropy = 0.865<br/>samples = 223<br/>value = [159, 64]<br/>class = negative>, fillcolor="#efb489"] ;
1 -> 127 ;
128 [label=<X<SUB>126</SUB> &le; 0.5<br/>entropy = 0.977<br/>samples = 153<br/>value = [90, 63]<br/>class = negative>, fillcolor="#f7d9c4"] ;
127 -> 128 ;
129 [label=<X<SUB>134</SUB> &le; 0.5<br/>entropy = 0.999<br/>samples = 119<br/>value = [57, 62]<br/>class = positive>, fillcolor="#eff7fd"] ;
128 -> 129 ;
130 [label=<X<SUB>172</SUB> &le; 0.5<br/>entropy = 0.998<br/>samples = 108<br/>value = [57, 51]<br/>class = negative>, fillcolor="#fcf2ea"] ;
129 -> 130 ;
131 [label=<X<SUB>104</SUB> &le; 0.5<br/>entropy = 0.875<br/>samples = 61<br/>value = [43, 18]<br/>class = negative>, fillcolor="#f0b68c"] ;
130 -> 131 ;
132 [label=<X<SUB>171</SUB> &le; 0.5<br/>entropy = 0.527<br/>samples = 42<br/>value = [37, 5]<br/>class = negative>, fillcolor="#e99254"] ;
131 -> 132 ;
133 [label=<X<SUB>144</SUB> &le; 0.5<br/>entropy = 0.297<br/>samples = 38<br/>value = [36, 2]<br/>class = negative>, fillcolor="#e68844"] ;
132 -> 133 ;
134 [label=<X<SUB>121</SUB> &le; 0.5<br/>entropy = 0.179<br/>samples = 37<br/>value = [36, 1]<br/>class = negative>, fillcolor="#e6843e"] ;
133 -> 134 ;
135 [label=<entropy = 0.0<br/>samples = 35<br/>value = [35, 0]<br/>class = negative>, fillcolor="#e58139"] ;
134 -> 135 ;
136 [label=<entropy = 1.0<br/>samples = 2<br/>value = [1, 1]<br/>class = negative>, fillcolor="#ffffff"] ;
134 -> 136 ;
137 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = positive>, fillcolor="#399de5"] ;
133 -> 137 ;
138 [label=<X<SUB>20</SUB> &le; 0.5<br/>entropy = 0.811<br/>samples = 4<br/>value = [1, 3]<br/>class = positive>, fillcolor="#7bbeee"] ;
132 -> 138 ;
139 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = positive>, fillcolor="#399de5"] ;
138 -> 139 ;
140 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = negative>, fillcolor="#e58139"] ;
138 -> 140 ;
141 [label=<X<SUB>2</SUB> &le; 0.5<br/>entropy = 0.9<br/>samples = 19<br/>value = [6, 13]<br/>class = positive>, fillcolor="#94caf1"] ;
131 -> 141 ;
142 [label=<X<SUB>76</SUB> &le; 0.5<br/>entropy = 0.787<br/>samples = 17<br/>value = [4, 13]<br/>class = positive>, fillcolor="#76bbed"] ;
141 -> 142 ;
143 [label=<X<SUB>63</SUB> &le; 0.5<br/>entropy = 0.592<br/>samples = 14<br/>value = [2, 12]<br/>class = positive>, fillcolor="#5aade9"] ;
142 -> 143 ;
144 [label=<entropy = 0.391<br/>samples = 13<br/>value = [1, 12]<br/>class = positive>, fillcolor="#49a5e7"] ;
143 -> 144 ;
145 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = negative>, fillcolor="#e58139"] ;
143 -> 145 ;
146 [label=<X<SUB>114</SUB> &le; 0.5<br/>entropy = 0.918<br/>samples = 3<br/>value = [2, 1]<br/>class = negative>, fillcolor="#f2c09c"] ;
142 -> 146 ;
147 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = positive>, fillcolor="#399de5"] ;
146 -> 147 ;
148 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0]<br/>class = negative>, fillcolor="#e58139"] ;
146 -> 148 ;
149 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0]<br/>class = negative>, fillcolor="#e58139"] ;
141 -> 149 ;
150 [label=<X<SUB>26</SUB> &le; 0.5<br/>entropy = 0.879<br/>samples = 47<br/>value = [14, 33]<br/>class = positive>, fillcolor="#8dc7f0"] ;
130 -> 150 ;
151 [label=<X<SUB>19</SUB> &le; 0.5<br/>entropy = 0.732<br/>samples = 39<br/>value = [8, 31]<br/>class = positive>, fillcolor="#6cb6ec"] ;
150 -> 151 ;
152 [label=<X<SUB>65</SUB> &le; 0.5<br/>entropy = 0.581<br/>samples = 36<br/>value = [5, 31]<br/>class = positive>, fillcolor="#59ade9"] ;
151 -> 152 ;
153 [label=<X<SUB>75</SUB> &le; 0.5<br/>entropy = 0.513<br/>samples = 35<br/>value = [4, 31]<br/>class = positive>, fillcolor="#53aae8"] ;
152 -> 153 ;
154 [label=<entropy = 0.863<br/>samples = 7<br/>value = [2, 5]<br/>class = positive>, fillcolor="#88c4ef"] ;
153 -> 154 ;
155 [label=<entropy = 0.371<br/>samples = 28<br/>value = [2, 26]<br/>class = positive>, fillcolor="#48a5e7"] ;
153 -> 155 ;
156 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = negative>, fillcolor="#e58139"] ;
152 -> 156 ;
157 [label=<entropy = 0.0<br/>samples = 3<br/>value = [3, 0]<br/>class = negative>, fillcolor="#e58139"] ;
151 -> 157 ;
158 [label=<X<SUB>156</SUB> &le; 0.5<br/>entropy = 0.811<br/>samples = 8<br/>value = [6, 2]<br/>class = negative>, fillcolor="#eeab7b"] ;
150 -> 158 ;
159 [label=<X<SUB>55</SUB> &le; 0.5<br/>entropy = 0.592<br/>samples = 7<br/>value = [6, 1]<br/>class = negative>, fillcolor="#e9965a"] ;
158 -> 159 ;
160 [label=<X<SUB>24</SUB> &le; 0.5<br/>entropy = 0.722<br/>samples = 5<br/>value = [4, 1]<br/>class = negative>, fillcolor="#eca06a"] ;
159 -> 160 ;
161 [label=<entropy = 0.918<br/>samples = 3<br/>value = [2, 1]<br/>class = negative>, fillcolor="#f2c09c"] ;
160 -> 161 ;
162 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0]<br/>class = negative>, fillcolor="#e58139"] ;
160 -> 162 ;
163 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0]<br/>class = negative>, fillcolor="#e58139"] ;
159 -> 163 ;
164 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = positive>, fillcolor="#399de5"] ;
158 -> 164 ;
165 [label=<entropy = 0.0<br/>samples = 11<br/>value = [0, 11]<br/>class = positive>, fillcolor="#399de5"] ;
129 -> 165 ;
166 [label=<X<SUB>155</SUB> &le; 0.5<br/>entropy = 0.191<br/>samples = 34<br/>value = [33, 1]<br/>class = negative>, fillcolor="#e6853f"] ;
128 -> 166 ;
167 [label=<entropy = 0.0<br/>samples = 29<br/>value = [29, 0]<br/>class = negative>, fillcolor="#e58139"] ;
166 -> 167 ;
168 [label=<X<SUB>2</SUB> &le; 0.5<br/>entropy = 0.722<br/>samples = 5<br/>value = [4, 1]<br/>class = negative>, fillcolor="#eca06a"] ;
166 -> 168 ;
169 [label=<X<SUB>100</SUB> &le; 0.5<br/>entropy = 1.0<br/>samples = 2<br/>value = [1, 1]<br/>class = negative>, fillcolor="#ffffff"] ;
168 -> 169 ;
170 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = positive>, fillcolor="#399de5"] ;
169 -> 170 ;
171 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = negative>, fillcolor="#e58139"] ;
169 -> 171 ;
172 [label=<entropy = 0.0<br/>samples = 3<br/>value = [3, 0]<br/>class = negative>, fillcolor="#e58139"] ;
168 -> 172 ;
173 [label=<X<SUB>78</SUB> &le; 0.5<br/>entropy = 0.108<br/>samples = 70<br/>value = [69, 1]<br/>class = negative>, fillcolor="#e5833c"] ;
127 -> 173 ;
174 [label=<entropy = 0.0<br/>samples = 68<br/>value = [68, 0]<br/>class = negative>, fillcolor="#e58139"] ;
173 -> 174 ;
175 [label=<X<SUB>100</SUB> &le; 0.5<br/>entropy = 1.0<br/>samples = 2<br/>value = [1, 1]<br/>class = negative>, fillcolor="#ffffff"] ;
173 -> 175 ;
176 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = positive>, fillcolor="#399de5"] ;
175 -> 176 ;
177 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = negative>, fillcolor="#e58139"] ;
175 -> 177 ;
178 [label=<X<SUB>95</SUB> &le; 0.5<br/>entropy = 0.933<br/>samples = 315<br/>value = [205, 110]<br/>class = negative>, fillcolor="#f3c5a3"] ;
0 -> 178 [labeldistance=2.5, labelangle=-45, headlabel="False"] ;
179 [label=<X<SUB>124</SUB> &le; 0.5<br/>entropy = 0.742<br/>samples = 190<br/>value = [150, 40]<br/>class = negative>, fillcolor="#eca36e"] ;
178 -> 179 ;
180 [label=<X<SUB>138</SUB> &le; 0.5<br/>entropy = 0.824<br/>samples = 155<br/>value = [115, 40]<br/>class = negative>, fillcolor="#eead7e"] ;
179 -> 180 ;
181 [label=<X<SUB>181</SUB> &le; 0.5<br/>entropy = 0.885<br/>samples = 132<br/>value = [92, 40]<br/>class = negative>, fillcolor="#f0b88f"] ;
180 -> 181 ;
182 [label=<X<SUB>151</SUB> &le; 0.5<br/>entropy = 0.921<br/>samples = 119<br/>value = [79, 40]<br/>class = negative>, fillcolor="#f2c19d"] ;
181 -> 182 ;
183 [label=<X<SUB>23</SUB> &le; 0.5<br/>entropy = 0.897<br/>samples = 115<br/>value = [79, 36]<br/>class = negative>, fillcolor="#f1ba93"] ;
182 -> 183 ;
184 [label=<X<SUB>176</SUB> &le; 0.5<br/>entropy = 0.807<br/>samples = 89<br/>value = [67, 22]<br/>class = negative>, fillcolor="#eeaa7a"] ;
183 -> 184 ;
185 [label=<X<SUB>131</SUB> &le; 0.5<br/>entropy = 0.762<br/>samples = 86<br/>value = [67, 19]<br/>class = negative>, fillcolor="#eca571"] ;
184 -> 185 ;
186 [label=<X<SUB>3</SUB> &le; 0.5<br/>entropy = 0.655<br/>samples = 77<br/>value = [64, 13]<br/>class = negative>, fillcolor="#ea9b61"] ;
185 -> 186 ;
187 [label=<entropy = 0.601<br/>samples = 75<br/>value = [64, 11]<br/>class = negative>, fillcolor="#e9975b"] ;
186 -> 187 ;
188 [label=<entropy = 0.0<br/>samples = 2<br/>value = [0, 2]<br/>class = positive>, fillcolor="#399de5"] ;
186 -> 188 ;
189 [label=<X<SUB>42</SUB> &le; 0.5<br/>entropy = 0.918<br/>samples = 9<br/>value = [3, 6]<br/>class = positive>, fillcolor="#9ccef2"] ;
185 -> 189 ;
190 [label=<entropy = 0.592<br/>samples = 7<br/>value = [1, 6]<br/>class = positive>, fillcolor="#5aade9"] ;
189 -> 190 ;
191 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0]<br/>class = negative>, fillcolor="#e58139"] ;
189 -> 191 ;
192 [label=<entropy = 0.0<br/>samples = 3<br/>value = [0, 3]<br/>class = positive>, fillcolor="#399de5"] ;
184 -> 192 ;
193 [label=<X<SUB>48</SUB> &le; 0.5<br/>entropy = 0.996<br/>samples = 26<br/>value = [12, 14]<br/>class = positive>, fillcolor="#e3f1fb"] ;
183 -> 193 ;
194 [label=<entropy = 0.0<br/>samples = 3<br/>value = [3, 0]<br/>class = negative>, fillcolor="#e58139"] ;
193 -> 194 ;
195 [label=<X<SUB>147</SUB> &le; 0.5<br/>entropy = 0.966<br/>samples = 23<br/>value = [9, 14]<br/>class = positive>, fillcolor="#b8dcf6"] ;
193 -> 195 ;
196 [label=<X<SUB>62</SUB> &le; 0.5<br/>entropy = 0.918<br/>samples = 21<br/>value = [7, 14]<br/>class = positive>, fillcolor="#9ccef2"] ;
195 -> 196 ;
197 [label=<entropy = 0.544<br/>samples = 8<br/>value = [1, 7]<br/>class = positive>, fillcolor="#55abe9"] ;
196 -> 197 ;
198 [label=<entropy = 0.996<br/>samples = 13<br/>value = [6, 7]<br/>class = positive>, fillcolor="#e3f1fb"] ;
196 -> 198 ;
199 [label=<entropy = 0.0<br/>samples = 2<br/>value = [2, 0]<br/>class = negative>, fillcolor="#e58139"] ;
195 -> 199 ;
200 [label=<entropy = 0.0<br/>samples = 4<br/>value = [0, 4]<br/>class = positive>, fillcolor="#399de5"] ;
182 -> 200 ;
201 [label=<entropy = 0.0<br/>samples = 13<br/>value = [13, 0]<br/>class = negative>, fillcolor="#e58139"] ;
181 -> 201 ;
202 [label=<entropy = 0.0<br/>samples = 23<br/>value = [23, 0]<br/>class = negative>, fillcolor="#e58139"] ;
180 -> 202 ;
203 [label=<entropy = 0.0<br/>samples = 35<br/>value = [35, 0]<br/>class = negative>, fillcolor="#e58139"] ;
179 -> 203 ;
204 [label=<X<SUB>126</SUB> &le; 0.5<br/>entropy = 0.99<br/>samples = 125<br/>value = [55, 70]<br/>class = positive>, fillcolor="#d5eaf9"] ;
178 -> 204 ;
205 [label=<X<SUB>137</SUB> &le; 0.5<br/>entropy = 0.972<br/>samples = 117<br/>value = [47, 70]<br/>class = positive>, fillcolor="#bedff6"] ;
204 -> 205 ;
206 [label=<X<SUB>38</SUB> &le; 0.5<br/>entropy = 0.958<br/>samples = 113<br/>value = [43, 70]<br/>class = positive>, fillcolor="#b3d9f5"] ;
205 -> 206 ;
207 [label=<X<SUB>133</SUB> &le; 0.5<br/>entropy = 0.974<br/>samples = 106<br/>value = [43, 63]<br/>class = positive>, fillcolor="#c0e0f7"] ;
206 -> 207 ;
208 [label=<X<SUB>94</SUB> &le; 0.5<br/>entropy = 0.964<br/>samples = 103<br/>value = [40, 63]<br/>class = positive>, fillcolor="#b7dbf6"] ;
207 -> 208 ;
209 [label=<X<SUB>35</SUB> &le; 0.5<br/>entropy = 0.993<br/>samples = 84<br/>value = [38, 46]<br/>class = positive>, fillcolor="#ddeefa"] ;
208 -> 209 ;
210 [label=<X<SUB>62</SUB> &le; 0.5<br/>entropy = 0.999<br/>samples = 68<br/>value = [35, 33]<br/>class = negative>, fillcolor="#fef8f4"] ;
209 -> 210 ;
211 [label=<X<SUB>14</SUB> &le; 0.5<br/>entropy = 0.977<br/>samples = 51<br/>value = [30, 21]<br/>class = negative>, fillcolor="#f7d9c4"] ;
210 -> 211 ;
212 [label=<entropy = 0.863<br/>samples = 35<br/>value = [25, 10]<br/>class = negative>, fillcolor="#efb388"] ;
211 -> 212 ;
213 [label=<entropy = 0.896<br/>samples = 16<br/>value = [5, 11]<br/>class = positive>, fillcolor="#93caf1"] ;
211 -> 213 ;
214 [label=<X<SUB>14</SUB> &le; 0.5<br/>entropy = 0.874<br/>samples = 17<br/>value = [5, 12]<br/>class = positive>, fillcolor="#8bc6f0"] ;
210 -> 214 ;
215 [label=<entropy = 0.811<br/>samples = 16<br/>value = [4, 12]<br/>class = positive>, fillcolor="#7bbeee"] ;
214 -> 215 ;
216 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = negative>, fillcolor="#e58139"] ;
214 -> 216 ;
217 [label=<X<SUB>113</SUB> &le; 0.5<br/>entropy = 0.696<br/>samples = 16<br/>value = [3, 13]<br/>class = positive>, fillcolor="#67b4eb"] ;
209 -> 217 ;
218 [label=<X<SUB>98</SUB> &le; 0.5<br/>entropy = 0.567<br/>samples = 15<br/>value = [2, 13]<br/>class = positive>, fillcolor="#57ace9"] ;
217 -> 218 ;
219 [label=<entropy = 0.371<br/>samples = 14<br/>value = [1, 13]<br/>class = positive>, fillcolor="#48a5e7"] ;
218 -> 219 ;
220 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = negative>, fillcolor="#e58139"] ;
218 -> 220 ;
221 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = negative>, fillcolor="#e58139"] ;
217 -> 221 ;
222 [label=<X<SUB>169</SUB> &le; 0.5<br/>entropy = 0.485<br/>samples = 19<br/>value = [2, 17]<br/>class = positive>, fillcolor="#50a9e8"] ;
208 -> 222 ;
223 [label=<X<SUB>36</SUB> &le; 0.5<br/>entropy = 0.31<br/>samples = 18<br/>value = [1, 17]<br/>class = positive>, fillcolor="#45a3e7"] ;
222 -> 223 ;
224 [label=<entropy = 0.0<br/>samples = 16<br/>value = [0, 16]<br/>class = positive>, fillcolor="#399de5"] ;
223 -> 224 ;
225 [label=<X<SUB>107</SUB> &le; 0.5<br/>entropy = 1.0<br/>samples = 2<br/>value = [1, 1]<br/>class = negative>, fillcolor="#ffffff"] ;
223 -> 225 ;
226 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = negative>, fillcolor="#e58139"] ;
225 -> 226 ;
227 [label=<entropy = 0.0<br/>samples = 1<br/>value = [0, 1]<br/>class = positive>, fillcolor="#399de5"] ;
225 -> 227 ;
228 [label=<entropy = 0.0<br/>samples = 1<br/>value = [1, 0]<br/>class = negative>, fillcolor="#e58139"] ;
222 -> 228 ;
229 [label=<entropy = 0.0<br/>samples = 3<br/>value = [3, 0]<br/>class = negative>, fillcolor="#e58139"] ;
207 -> 229 ;
230 [label=<entropy = 0.0<br/>samples = 7<br/>value = [0, 7]<br/>class = positive>, fillcolor="#399de5"] ;
206 -> 230 ;
231 [label=<entropy = 0.0<br/>samples = 4<br/>value = [4, 0]<br/>class = negative>, fillcolor="#e58139"] ;
205 -> 231 ;
232 [label=<entropy = 0.0<br/>samples = 8<br/>value = [8, 0]<br/>class = negative>, fillcolor="#e58139"] ;
204 -> 232 ;
}